{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_-_vs_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJXZyGoZM58KkpM1Mq8anb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/birdx0810/LearningTensorFlow/blob/main/TensorFlow___vs_PyTorch_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77hmKpSpwu0w",
        "outputId": "384bf3a9-20c6-4e6f-c6ac-29b76557a0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "from tqdm import trange\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSeNwLIGDBgP",
        "outputId": "668648e0-b711-4fe3-8b85-859802573a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set random seed\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.compat.v1.set_random_seed(42)\n",
        "\n",
        "with open(\"sample_data/anscombe.json\", \"r\") as f:\n",
        "  tmp = json.load(f)\n",
        "\n",
        "d1 = []\n",
        "d2 = []\n",
        "d3 = []\n",
        "d4 = []\n",
        "\n",
        "for d in tmp:\n",
        "  if d['Series'] == 'I':\n",
        "    d1.append([d[\"X\"], d[\"Y\"]])\n",
        "  if d['Series'] == 'II':\n",
        "    d2.append([d[\"X\"], d[\"Y\"]])\n",
        "  if d['Series'] == 'III':\n",
        "    d3.append([d[\"X\"], d[\"Y\"]])\n",
        "  if d['Series'] == 'IV':\n",
        "    d4.append([d[\"X\"], d[\"Y\"]])\n",
        "\n",
        "data = np.concatenate([[d1], [d2], [d3], [d4]])\n",
        "print(data.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 11, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iynH5ix3zdRw"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "epochs = 10\n",
        "batch_size = 2\n",
        "\n",
        "num_layers = 2\n",
        "max_seq_len = 11\n",
        "input_dim = 2\n",
        "hidden_dim = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8RhU1z71Cxq"
      },
      "source": [
        "def get_batch(x, iteration, batch_size):\n",
        "  time = [len(x[i][:,0]) for i in range(len(x))]\n",
        "\n",
        "  start = iteration * batch_size\n",
        "  end = start + batch_size\n",
        "\n",
        "  x_mb = x[start:end]\n",
        "  t_mb = time[start:end]\n",
        "\n",
        "  return x_mb, t_mb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPzcn-e4D0zW"
      },
      "source": [
        "## TensorFlow 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mG6fEyzD0Mj",
        "outputId": "35752e64-715a-48e1-beba-28f2e85b0eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "enc_rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=hidden_dim, activation=tf.nn.tanh)\n",
        "dec_rnn_cell = tf.nn.rnn_cell.GRUCell(num_units=input_dim, activation=tf.nn.tanh)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-6e11b295c40b>:1: GRUCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVHnASmyx8Dm"
      },
      "source": [
        "def model(data):\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  # Input place holders\n",
        "  X = tf.placeholder(tf.float32, [None, max_seq_len, input_dim])\n",
        "  S = tf.placeholder(tf.float32, [None])\n",
        "\n",
        "  def encoder (X, S):\n",
        "    with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
        "\n",
        "      e_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(num_units=hidden_dim, activation=tf.nn.tanh) for _ in range(num_layers)])\n",
        "\n",
        "      e_outputs, e_last_states = tf.nn.dynamic_rnn(e_cell, X, dtype=tf.float32, sequence_length=S)\n",
        "\n",
        "      H = tf.layers.dense(e_outputs, hidden_dim, activation=tf.nn.sigmoid)\n",
        "    \n",
        "    return H\n",
        "        \n",
        "  def decoder (H, S):\n",
        "    with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
        "\n",
        "      r_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(num_units=input_dim, activation=tf.nn.tanh) for _ in range(num_layers)])\n",
        "\n",
        "      r_outputs, r_last_states = tf.nn.dynamic_rnn(r_cell, H, dtype=tf.float32, sequence_length=S)\n",
        "\n",
        "      X_tilde = tf.layers.dense(r_outputs, input_dim, activation=None)\n",
        "    \n",
        "    return X_tilde\n",
        "\n",
        "  H = encoder(X, S)\n",
        "  X_tilde = decoder(H, S)\n",
        "\n",
        "  loss = tf.losses.mean_squared_error(X, X_tilde)\n",
        "\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "  # Initializing the variables \n",
        "  init_global = tf.global_variables_initializer()\n",
        "  init_local = tf.local_variables_initializer()\n",
        "\n",
        "  # Launch the graph \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init_global)\n",
        "    sess.run(init_local)\n",
        "    \n",
        "    # Training cycle\n",
        "    for epoch in range(epochs):\n",
        "      total_loss = 0.\n",
        "      iterations = int(len(data)/batch_size)\n",
        "\n",
        "      for i in trange(iterations):\n",
        "        # Get mini batch\n",
        "        batch_xs, batch_ts = get_batch(data, i, batch_size)\n",
        "        \n",
        "        # Fit training using batch data \n",
        "        _, batch_loss = sess.run([optimizer, loss], feed_dict={X: batch_xs, S: batch_ts})\n",
        "\n",
        "        total_loss += batch_loss/iterations\n",
        "      \n",
        "      print(f\"\\nEpoch: {epoch}\\tLoss: {total_loss}\")\n",
        "      \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPmSB7z11RkV",
        "outputId": "289c1ceb-006c-412a-e821-666f0949be9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "source": [
        "model(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-f86b142d99e9>:11: MultiRNNCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-6-f86b142d99e9>:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:564: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:570: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:580: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-6-f86b142d99e9>:15: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  4.07it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 96.95it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 95.90it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 83.08it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 92.56it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 92.40it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 88.87it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 93.65it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\tLoss: 74.75547790527344\n",
            "\n",
            "Epoch: 1\tLoss: 74.64163970947266\n",
            "\n",
            "Epoch: 2\tLoss: 74.52843856811523\n",
            "\n",
            "Epoch: 3\tLoss: 74.41592407226562\n",
            "\n",
            "Epoch: 4\tLoss: 74.30418014526367\n",
            "\n",
            "Epoch: 5\tLoss: 74.19321823120117\n",
            "\n",
            "Epoch: 6\tLoss: 74.0830078125\n",
            "\n",
            "Epoch: 7\tLoss: 73.97346115112305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 78.14it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 62.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 8\tLoss: 73.86439895629883\n",
            "\n",
            "Epoch: 9\tLoss: 73.75564575195312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWo2DGwxFEE1"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bCieIOJDEL",
        "outputId": "673652f7-6010-411b-82d1-c21a28752af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb78ed94d08>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT7o07QWDxIo"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.emb_rnn = torch.nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "    self.emb_linear = torch.nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.emb_sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    H_o, H_t = self.emb_rnn(X)\n",
        "    logits = self.emb_linear(H_o)\n",
        "    H = self.emb_sigmoid(logits)\n",
        "    return H\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.rec_rnn = torch.nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "    self.rec_linear = torch.nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "  def forward(self, H):\n",
        "    H_o, H_t = self.rec_rnn(H)\n",
        "    X_tilde = self.rec_linear(H_o)\n",
        "    return X_tilde\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "    self.criterion = torch.nn.MSELoss()\n",
        "\n",
        "  def forward(self, X):\n",
        "    H = self.encoder(X)\n",
        "    X_tilde = self.decoder(H)\n",
        "    loss = self.criterion(X_tilde, X)\n",
        "    return loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9WEvWJmIfkS",
        "outputId": "1225ae39-5539-42cb-c7c7-4cc036a134ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "model = Model()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  iterations = int(len(data)/batch_size)\n",
        "  for i in trange(iterations):\n",
        "    model.zero_grad()\n",
        "    # Get mini batch\n",
        "    batch_xs, _ = get_batch(data, i, batch_size)\n",
        "    batch_xs = torch.Tensor(batch_xs)\n",
        "    loss = model(batch_xs)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  print(f\"\\nEpoch: {epoch}\\tLoss: {loss}\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 66.28it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 89.43it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 76.79it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 76.95it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 78.47it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 75.12it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 77.41it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 75.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\tLoss: 74.44517517089844\n",
            "\n",
            "Epoch: 1\tLoss: 74.10515594482422\n",
            "\n",
            "Epoch: 2\tLoss: 73.7649154663086\n",
            "\n",
            "Epoch: 3\tLoss: 73.42491912841797\n",
            "\n",
            "Epoch: 4\tLoss: 73.08519744873047\n",
            "\n",
            "Epoch: 5\tLoss: 72.74502563476562\n",
            "\n",
            "Epoch: 6\tLoss: 72.40290069580078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2/2 [00:00<00:00, 71.10it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 82.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 7\tLoss: 72.05651092529297\n",
            "\n",
            "Epoch: 8\tLoss: 71.70309448242188\n",
            "\n",
            "Epoch: 9\tLoss: 71.33988189697266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Ey-rlCJsxT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}