{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_-_From_1_To_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPatHrElR+0RemT8q3wAOv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/birdx0810/LearningTensorFlow/blob/main/TensorFlow___From_1_To_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBn8NWTYy7Xr"
      },
      "source": [
        "# TensorFlow: From 1.x to 2.x\n",
        "\n",
        "This is notebook is basically an implementation of a basic multi-layer perceptron using TF1.0 and TF2.0 method for MNIST dataset classification. The results should be similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7TeNpn9yMh5"
      },
      "source": [
        "import time\n",
        "\n",
        "# Import MINST data \n",
        "from keras.datasets import mnist\n",
        "from tqdm import trange\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb2S3hVmyrTj"
      },
      "source": [
        "# Set Model Parameters\n",
        "learning_rate = 1e-5 \n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "num_labels = 10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFGqosW4n9XJ"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4Rg_JoM6fh"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "\n",
        "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1]*train_x.shape[2])\n",
        "test_x = test_x.reshape(test_x.shape[0], test_x.shape[1]*test_x.shape[2])\n",
        "\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(range(num_labels))\n",
        "\n",
        "train_y = label_binarizer.transform(train_y)\n",
        "test_y = label_binarizer.transform(test_y)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_dT9dCynUYx",
        "outputId": "e4ac234e-1171-4546-cd34-e6b956e64e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCPCRVkaIGNx"
      },
      "source": [
        "def get_batch(x, y, iteration, batch_size):\n",
        "  \n",
        "  start = iteration * batch_size\n",
        "  end = start + batch_size\n",
        "\n",
        "  x_mb = x[start:end]\n",
        "  y_mb = y[start:end]\n",
        "  \n",
        "  return x_mb, y_mb"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg-z-_INzmfZ"
      },
      "source": [
        "## TensorFlow 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hXdrN8iz1Sf",
        "outputId": "06b903ff-0c69-492b-a9c7-7df43dce0b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# tf Graph Input \n",
        "x = tf.placeholder(\"float\", [None, 784])  # mnist data image of shape 28*28 = 784 \n",
        "y = tf.placeholder(\"float\", [None, 10])   # 0-9 digits recognition => 10 classes\n",
        "\n",
        "# Set model weight and bias \n",
        "W = tf.Variable(tf.ones([784, 10]))      # 784 -> 10 \n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "logits = tf.matmul(x, W) + b\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "\n",
        "pred = tf.nn.softmax(logits)\n",
        "acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(y,1), predictions=tf.argmax(pred,1))\n",
        "\n",
        "# Optimize model using gradient descent\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m24rX6aR1CEb",
        "outputId": "063f7069-14f8-4ee5-d78d-c323d1a0e7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# Initializing the variables \n",
        "init_global = tf.global_variables_initializer()\n",
        "init_local = tf.local_variables_initializer()\n",
        "\n",
        "# Launch the graph \n",
        "with tf.Session() as sess:\n",
        "  sess.run(init_global)\n",
        "  sess.run(init_local)\n",
        "  \n",
        "  # Training cycle\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0.\n",
        "    iterations = int(len(train_x)/batch_size)\n",
        "    c = 0\n",
        "    output = []\n",
        "    # Loop over all batches\n",
        "    for i in trange(iterations):\n",
        "      # Get mini batch\n",
        "      batch_xs, batch_ys = get_batch(train_x, train_y, i, batch_size)\n",
        "      \n",
        "      # Fit training using batch data \n",
        "      _, batch_loss = sess.run([optimizer, loss], feed_dict={x: batch_xs, y: batch_ys})\n",
        "\n",
        "      total_loss += batch_loss/iterations\n",
        "\n",
        "    # Display logs per epoch step\n",
        "    total_loss = total_loss\n",
        "    print(f\"\\nEpoch:{epoch+1}\\ttotal loss={total_loss}\")\n",
        "    time.sleep(.25)\n",
        "\n",
        "  _, accuracy = sess.run([acc, acc_op], feed_dict={x: test_x, y: test_y})\n",
        "  print(f\"model acc: {accuracy}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1129.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:1\ttotal loss=0.3842634023229276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1193.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:2\ttotal loss=0.29923564769526273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1173.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:3\ttotal loss=0.28795584580202827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1219.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:4\ttotal loss=0.28166802314718553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1217.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:5\ttotal loss=0.2773866816326977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1195.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:6\ttotal loss=0.27417149759829007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1198.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:7\ttotal loss=0.27163134654661053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1199.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:8\ttotal loss=0.2695258501455186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1208.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:9\ttotal loss=0.26775032064914717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:01<00:00, 1209.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:10\ttotal loss=0.26621794080386546\n",
            "model acc: 0.9174000024795532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc2iEcemjn6u"
      },
      "source": [
        "## TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho7shoW-jx8_",
        "outputId": "272a2310-aec1-4d77-fdbf-42ad3c53cd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Import relevant packages\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "# First define the model \n",
        "model = Sequential()\n",
        "\n",
        "# Add the dense layer to the model\n",
        "model.add(tf.keras.layers.Dense(\n",
        "  units=num_labels, \n",
        "  activation=\"softmax\", \n",
        "  input_shape=(784,), \n",
        "  weights=[np.ones([784, 10]), np.zeros(10)]\n",
        "))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTLPCpi1tiCs"
      },
      "source": [
        "# Define loss and optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "criterion = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model.compile(optimizer=optimizer, metrics=[\"accuracy\"], loss=criterion)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vv5LQSvtt_Q",
        "outputId": "0be2858f-800b-45e8-9517-2bcfbcb51b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "train_history = model.fit(\n",
        "  train_x, train_y, \n",
        "  batch_size=batch_size, epochs=epochs\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3776 - acc: 0.8988\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2908 - acc: 0.9189\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2815 - acc: 0.9211\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2737 - acc: 0.9234\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2690 - acc: 0.9258\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2666 - acc: 0.9264\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2627 - acc: 0.9273\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2610 - acc: 0.9280\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2601 - acc: 0.9279\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2574 - acc: 0.9295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4jmmiVZvVnR",
        "outputId": "9166fbbb-1eb4-46e2-f874-2937b647c96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_x, test_y)\n",
        "print(f\"Acc: {accuracy}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "Acc: 0.9253000020980835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kejSzQ21zuRR"
      },
      "source": [
        "# get_output = tf.keras.backend.function([model.layers[0].input],[model.layers[0].output])\n",
        "# layer_output = get_output(train_x)\n",
        "\n",
        "# print(*layer_output, sep=\"\\n\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgY0Anlb1MZ2"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}